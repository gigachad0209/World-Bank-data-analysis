{"cells":[{"cell_type":"markdown","metadata":{"id":"XeR6kqRKlxR8"},"source":["## Lab01: Collect and preprocess data\n","\n","- Name: Trương Công Gia Phát\n","- Student code: 21127667"]},{"cell_type":"markdown","metadata":{"id":"JjC4xgumlxR_"},"source":["***\n","## How to do and submit your assignment\n","\n","**Work on your assignment**\n","\n","You will do your assignment directly in this notebook. First, fill in your name and ID at the beginning of the file. In the notebook, fill in places that say:\n","```python\n","#TODO\n","```\n","\n","During your work, you can print out the result, create more cells to test, or create more functions to handle things. Please note that <font color=red>you are not allowed to delete or modify my code cells</font> (except in the case that mentioned above). Let remove `raise NotImplementedError(\"not implement\")` when running code.\n","\n","Always press `Ctrl + S` in order to save your work.\n","\n","**Notes:**\n","\n","    *  Copy means zero\n","    *  You have to submit your work on time. No exception\n","    *  Any questions about your grade are based on the assignment submitted on Moodle\n","    *  Wrong submission takes you -2 points\n","\n","**Submission guideline**\n","\n","When grading your assignment, I will choose `Kernel` - `Restart Kernel & Run All Cells` in order to restart the kernel and run all cells in your notebook. Therefore, you should do that before submitting to ensure that the outputs are all as expected.\n","\n","After that, you make a submited direction as follow:\n","\n","- Folder `StudentCode` (e.g. If your student code is 1234567, then your folder is `1234567`)\n","    - File `<StudentCode>.ipynb` (e.g. If your student code is 1234567, then your file is `1234567.ipynb`)\n","\n","Finally, you compress your folder (`StudentCode`) and submit on Moodle. **The extension of the file is nothing else but `.zip`.**\n","\n","<font color=red>Please strictly follow the submission rules.</font>"]},{"cell_type":"markdown","metadata":{"id":"B8GTf2adlxSA"},"source":["# 1. Set-up environment"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rYiDPimvlxSB"},"outputs":[],"source":["#Necessary Packages\n","import time\n","import requests\n","import numpy as np\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","# YOUR CODE HERE (OPTION)\n","# If you need other support packages"]},{"cell_type":"markdown","metadata":{"id":"EF1kaxXYlxSF"},"source":["# 2. Collect data from a website by parsing HTML (3p)"]},{"cell_type":"markdown","metadata":{"id":"y4JNe6ZXlxSG"},"source":["In this section, you are going to collect data from a website simulating the sale of Pokemon. I have prepared all the needed links in a file (`pokemon.txt`), and you have to crawl data from these links. The expected output is a `dataframe` with the following fields:\n","\n","+ `SKU`: ID of Pokemon\n","+ `Name`: Name of Pokemon\n","+ `Price`: Price of Pokemon\n","+ `InStock`: Quantity of Pokemons in stock\n","+ `Categories`: The category of Pokemon\n","+ `Tags`: Tags of Pokemon\n","\n","Your mission is to complete function `collect_data` with `course_urls_file` as your input parameter. The output should look like `pokemon_example.csv` (I list out some examples so you can easily imagine your work)."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lCqUDtbclxSH","outputId":"deb45daf-ed42-466d-9886-1fe752e3a64d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SKU</th>\n","      <th>Name</th>\n","      <th>Price</th>\n","      <th>InStock</th>\n","      <th>Categories</th>\n","      <th>Tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4391</td>\n","      <td>Bulbasaur</td>\n","      <td>63.0</td>\n","      <td>45</td>\n","      <td>Pokemon, Seed</td>\n","      <td>bulbasaur, Overgrow, Seed</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7227</td>\n","      <td>Ivysaur</td>\n","      <td>87.0</td>\n","      <td>142</td>\n","      <td>Pokemon, Seed</td>\n","      <td>ivysaur, Overgrow, Seed</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7036</td>\n","      <td>Venusaur</td>\n","      <td>105.0</td>\n","      <td>30</td>\n","      <td>Pokemon, Seed</td>\n","      <td>Overgrow, Seed, venusaur</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9086</td>\n","      <td>Charmander</td>\n","      <td>48.0</td>\n","      <td>206</td>\n","      <td>Lizard, Pokemon</td>\n","      <td>Blaze, charmander, Lizard</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6565</td>\n","      <td>Charmeleon</td>\n","      <td>165.0</td>\n","      <td>284</td>\n","      <td>Flame, Pokemon</td>\n","      <td>Blaze, charmeleon, Flame</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    SKU        Name  Price  InStock       Categories  \\\n","0  4391   Bulbasaur   63.0       45    Pokemon, Seed   \n","1  7227     Ivysaur   87.0      142    Pokemon, Seed   \n","2  7036    Venusaur  105.0       30    Pokemon, Seed   \n","3  9086  Charmander   48.0      206  Lizard, Pokemon   \n","4  6565  Charmeleon  165.0      284   Flame, Pokemon   \n","\n","                        Tags  \n","0  bulbasaur, Overgrow, Seed  \n","1    ivysaur, Overgrow, Seed  \n","2   Overgrow, Seed, venusaur  \n","3  Blaze, charmander, Lizard  \n","4   Blaze, charmeleon, Flame  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["pokemon_example = pd.read_csv('pokemon_example.csv')\n","pokemon_example"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"y5ZXiT6PlxSJ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Bulbasaur\n"]}],"source":["def collect_data(course_urls_file):\n","    #load paths from file\n","    url_file = open(course_urls_file)\n","    urls = url_file.readlines()\n","    urls_filtered = [item[:-1] for item in urls]\n","\n","    #init empty list to store the values of each attribute.\n","    SKU = []\n","    Names = []\n","    Prices = []\n","    InStocks = []\n","    Categories = []\n","    Tags = []\n","\n","    for url in urls_filtered:\n","        html_text = requests.get(url).text\n","        soup = BeautifulSoup(html_text, 'lxml')\n","        name_line = str(soup.find('h1', 'product_title entry-title'))\n","        name = name_line.split(\">\")[1].split(\"<\")[0]\n","        price_line = str(soup.find('p','price'))\n","        price = price_line.split(\">\")[4].split(\"<\")[0]\n","        sku_line = str(soup.find('span', 'sku'))\n","        sku = sku_line.split(\">\")[1].split(\"<\")[0]\n","        inStock_line = str(soup.find('p', 'stock in-stock'))\n","        inStock = inStock_line.split('>')[1].split('in stock')[0]\n","        categories_line = str(soup.find('span', 'posted_in')).split('Categories:')[1]\n","        categories = []\n","        for x in categories_line.split(','):\n","            categories.append(x.split('>')[1].split('<')[0])\n","\n","        categories_str = ''\n","        for x in categories:\n","            if x == categories[-1]:\n","                categories_str = categories_str + x\n","            else: categories_str = categories_str + x + ', '\n","\n","        tags_line = str(soup.find('span', 'tagged_as')).split('Tags:')[1]\n","        tags = []\n","        for x in tags_line.split(','):\n","            tags.append(x.split('>')[1].split('<')[0])\n","\n","        tags_str = ''\n","        for x in tags:\n","            if x == tags[-1]:\n","                tags_str = tags_str + x\n","            else: tags_str = tags_str + x + ', '\n","        \n","        SKU.append(sku)\n","        Names.append(name)\n","        Prices.append(price)\n","        InStocks.append(inStock)\n","        Categories.append(categories_str)\n","        Tags.append(tags_str)\n","    #raise NotImplementedError(\"not implement\")\n","\n","    data = pd.DataFrame({\"SKU\": SKU,\n","                         \"Name\": Names,\n","                         \"Price\": Prices,\n","                         \"InStock\": InStocks,\n","                         \"Categories\": Categories,\n","                         \"Tags\": Tags})\n","\n","    return data\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"pxQaHCuKlxSK"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SKU</th>\n","      <th>Name</th>\n","      <th>Price</th>\n","      <th>InStock</th>\n","      <th>Categories</th>\n","      <th>Tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4391</td>\n","      <td>Bulbasaur</td>\n","      <td>63.00</td>\n","      <td>45</td>\n","      <td>Pokemon, Seed</td>\n","      <td>bulbasaur, Overgrow, Seed</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7227</td>\n","      <td>Ivysaur</td>\n","      <td>87.00</td>\n","      <td>142</td>\n","      <td>Pokemon, Seed</td>\n","      <td>ivysaur, Overgrow, Seed</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7036</td>\n","      <td>Venusaur</td>\n","      <td>105.00</td>\n","      <td>30</td>\n","      <td>Pokemon, Seed</td>\n","      <td>Overgrow, Seed, venusaur</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9086</td>\n","      <td>Charmander</td>\n","      <td>48.00</td>\n","      <td>206</td>\n","      <td>Lizard, Pokemon</td>\n","      <td>Blaze, charmander, Lizard</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6565</td>\n","      <td>Charmeleon</td>\n","      <td>165.00</td>\n","      <td>284</td>\n","      <td>Flame, Pokemon</td>\n","      <td>Blaze, charmeleon, Flame</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>8840</td>\n","      <td>Charizard</td>\n","      <td>156.00</td>\n","      <td>31</td>\n","      <td>Flame, Pokemon</td>\n","      <td>Blaze, Charizard, Flame</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6094</td>\n","      <td>Squirtle</td>\n","      <td>130.00</td>\n","      <td>178</td>\n","      <td>Pokemon, Tiny Turtle</td>\n","      <td>squirtle, Tiny Turtle, Torrent</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9659</td>\n","      <td>Wartortle</td>\n","      <td>123.00</td>\n","      <td>24</td>\n","      <td>Pokemon, Turtle</td>\n","      <td>Torrent, Turtle, wartortle</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5212</td>\n","      <td>Blastoise</td>\n","      <td>76.00</td>\n","      <td>88</td>\n","      <td>Pokemon, Shellfish</td>\n","      <td>blastoise, Shellfish, Torrent</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>7492</td>\n","      <td>Caterpie</td>\n","      <td>73.00</td>\n","      <td>40</td>\n","      <td>Pokemon, Worm</td>\n","      <td>caterpie, Shield Dust, Worm</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2072</td>\n","      <td>Metapod</td>\n","      <td>148.00</td>\n","      <td>285</td>\n","      <td>Cocoon, Pokemon</td>\n","      <td>Cocoon, metapod, Shed Skin</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     SKU        Name   Price InStock            Categories  \\\n","0   4391   Bulbasaur   63.00     45          Pokemon, Seed   \n","1   7227     Ivysaur   87.00    142          Pokemon, Seed   \n","2   7036    Venusaur  105.00     30          Pokemon, Seed   \n","3   9086  Charmander   48.00    206        Lizard, Pokemon   \n","4   6565  Charmeleon  165.00    284         Flame, Pokemon   \n","5   8840   Charizard  156.00     31         Flame, Pokemon   \n","6   6094    Squirtle  130.00    178   Pokemon, Tiny Turtle   \n","7   9659   Wartortle  123.00     24        Pokemon, Turtle   \n","8   5212   Blastoise   76.00     88     Pokemon, Shellfish   \n","9   7492    Caterpie   73.00     40          Pokemon, Worm   \n","10  2072     Metapod  148.00    285        Cocoon, Pokemon   \n","\n","                              Tags  \n","0        bulbasaur, Overgrow, Seed  \n","1          ivysaur, Overgrow, Seed  \n","2         Overgrow, Seed, venusaur  \n","3        Blaze, charmander, Lizard  \n","4         Blaze, charmeleon, Flame  \n","5          Blaze, Charizard, Flame  \n","6   squirtle, Tiny Turtle, Torrent  \n","7       Torrent, Turtle, wartortle  \n","8    blastoise, Shellfish, Torrent  \n","9      caterpie, Shield Dust, Worm  \n","10      Cocoon, metapod, Shed Skin  "]},"metadata":{},"output_type":"display_data"}],"source":["#TEST\n","data_pokemon = collect_data(\"pokemon.txt\")\n","assert data_pokemon.shape == (755, 6)\n","display(data_pokemon.head(11))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"mdeWdVTWlxSK"},"outputs":[],"source":["#Save to csv file with name pokemon.csv\n","data_pokemon.to_csv('pokemon.csv', index = False)"]},{"cell_type":"markdown","metadata":{"id":"Uy07c4velxSL"},"source":["# 3. Collect data using Web API (4p)"]},{"cell_type":"markdown","metadata":{"id":"qqoLHqyDlxSL"},"source":["In this section, your work is to practice to crawl data using Web API (http://api.worldbank.org/v2/country/all/indicator/SP.POP.TOTL). This is the data of World Bank which includes demographic data and other statistics related to Population, Employment, Health, GDP, Energy Consumption,... for all countries in the world from 1960 to 2022.\n","\n","From the following selected indicators:\n","- `SP.POP.TOTL` - Total population\n","- `SP.POP.TOTL.FE.IN` - Total female population\n","- `SP.POP.TOTL.MA.IN` - Total male population\n","- `SP.DYN.CBRT.IN` - Birth rate\n","- `SP.DYN.CDRT.IN` - Death rate\n","- `SP.DYN.LE00.MA.IN` - Average life expectancy of male\n","- `SP.DYN.LE00.FE.IN` - Average life expectancy of female\n","- `SE.PRM.ENRR` - Primary school enrollment rate\n","- `SE.TER.ENRR` - High school enrollment rate\n","- `SE.PRM.CMPT.ZS` - Primary completion rate\n","- `SE.ADT.1524.LT.ZS` - Literacy rate of people ages 15-24\n","\n","You are required to collect data from 7 countries and save to dataframe `data_countries`:\n","- `US` - United States of America\n","- `IN` - India\n","- `CN` - China\n","- `JP` - Japan\n","- `CA` - Canada\n","- `GB` - Great Britain\n","- `ZA` - South Africa\n","\n","You can expand your work on collecting data (such as collecting data from other countries and other indicators) by reading: https://datahelpdesk.worldbank.org/knowledgebase/articles/889392-api-documentation\n","\n","**Hints**:\n","\n","- Use the based URL: http://api.worldbank.org/v2/\n","- In order to collect data for each indicator of each country, you can use the URL: \"http://api.worldbank.org/v2/countries/{country_code}/indicators/{indicator_code}\"\n","    + `country_code` and `indicator_code` are provided above.\n","    + For example, you can use the following URL to get the `Total population` of Japan: http://api.worldbank.org/v2/countries/jp/indicators/SP.POP.TOTL"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ppyriUdZlxSM","outputId":"a2806113-3a8a-4ae4-960b-f610839bfe22"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Total Population</th>\n","      <th>Female Population</th>\n","      <th>Male Population</th>\n","      <th>Birth Rate</th>\n","      <th>Death Rate</th>\n","      <th>Male life expectancy</th>\n","      <th>Female life expectancy</th>\n","      <th>School enrollment, primary</th>\n","      <th>School enrollment, tertiary</th>\n","      <th>Primary completion rate</th>\n","      <th>Literacy rate</th>\n","      <th>Year</th>\n","      <th>Country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>333287557.0</td>\n","      <td>168266219.0</td>\n","      <td>165021339.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2022</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>332031554.0</td>\n","      <td>167550001.0</td>\n","      <td>164481553.0</td>\n","      <td>11.0</td>\n","      <td>10.400</td>\n","      <td>73.5</td>\n","      <td>79.3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2021</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>331511512.0</td>\n","      <td>167203010.0</td>\n","      <td>164308503.0</td>\n","      <td>10.9</td>\n","      <td>10.300</td>\n","      <td>74.2</td>\n","      <td>79.9</td>\n","      <td>100.305794</td>\n","      <td>87.567657</td>\n","      <td>100.923668</td>\n","      <td>NaN</td>\n","      <td>2020</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>328329953.0</td>\n","      <td>165599805.0</td>\n","      <td>162730147.0</td>\n","      <td>11.4</td>\n","      <td>8.700</td>\n","      <td>76.3</td>\n","      <td>81.4</td>\n","      <td>100.981300</td>\n","      <td>87.888710</td>\n","      <td>100.489052</td>\n","      <td>NaN</td>\n","      <td>2019</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>326838199.0</td>\n","      <td>164926348.0</td>\n","      <td>161911851.0</td>\n","      <td>11.6</td>\n","      <td>8.678</td>\n","      <td>76.2</td>\n","      <td>81.2</td>\n","      <td>101.256561</td>\n","      <td>88.299179</td>\n","      <td>100.092697</td>\n","      <td>NaN</td>\n","      <td>2018</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>325122128.0</td>\n","      <td>164151818.0</td>\n","      <td>160970309.0</td>\n","      <td>11.8</td>\n","      <td>8.638</td>\n","      <td>76.1</td>\n","      <td>81.1</td>\n","      <td>101.821442</td>\n","      <td>88.167389</td>\n","      <td>98.832199</td>\n","      <td>NaN</td>\n","      <td>2017</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>323071755.0</td>\n","      <td>163224028.0</td>\n","      <td>159847727.0</td>\n","      <td>12.2</td>\n","      <td>8.493</td>\n","      <td>76.1</td>\n","      <td>81.1</td>\n","      <td>101.362862</td>\n","      <td>88.835052</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2016</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>320738994.0</td>\n","      <td>162158414.0</td>\n","      <td>158580581.0</td>\n","      <td>12.4</td>\n","      <td>8.440</td>\n","      <td>76.3</td>\n","      <td>81.2</td>\n","      <td>100.299911</td>\n","      <td>88.889412</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2015</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>318386329.0</td>\n","      <td>161084758.0</td>\n","      <td>157301571.0</td>\n","      <td>12.5</td>\n","      <td>8.237</td>\n","      <td>76.5</td>\n","      <td>81.3</td>\n","      <td>99.673378</td>\n","      <td>88.626869</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2014</td>\n","      <td>USA</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>316059947.0</td>\n","      <td>160034189.0</td>\n","      <td>156025758.0</td>\n","      <td>12.4</td>\n","      <td>8.215</td>\n","      <td>76.4</td>\n","      <td>81.2</td>\n","      <td>99.455437</td>\n","      <td>88.726418</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2013</td>\n","      <td>USA</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Total Population  Female Population  Male Population  Birth Rate  \\\n","0       333287557.0        168266219.0      165021339.0         NaN   \n","1       332031554.0        167550001.0      164481553.0        11.0   \n","2       331511512.0        167203010.0      164308503.0        10.9   \n","3       328329953.0        165599805.0      162730147.0        11.4   \n","4       326838199.0        164926348.0      161911851.0        11.6   \n","5       325122128.0        164151818.0      160970309.0        11.8   \n","6       323071755.0        163224028.0      159847727.0        12.2   \n","7       320738994.0        162158414.0      158580581.0        12.4   \n","8       318386329.0        161084758.0      157301571.0        12.5   \n","9       316059947.0        160034189.0      156025758.0        12.4   \n","\n","   Death Rate  Male life expectancy  Female life expectancy   \\\n","0         NaN                   NaN                      NaN   \n","1      10.400                  73.5                     79.3   \n","2      10.300                  74.2                     79.9   \n","3       8.700                  76.3                     81.4   \n","4       8.678                  76.2                     81.2   \n","5       8.638                  76.1                     81.1   \n","6       8.493                  76.1                     81.1   \n","7       8.440                  76.3                     81.2   \n","8       8.237                  76.5                     81.3   \n","9       8.215                  76.4                     81.2   \n","\n","   School enrollment, primary  School enrollment, tertiary  \\\n","0                         NaN                          NaN   \n","1                         NaN                          NaN   \n","2                  100.305794                    87.567657   \n","3                  100.981300                    87.888710   \n","4                  101.256561                    88.299179   \n","5                  101.821442                    88.167389   \n","6                  101.362862                    88.835052   \n","7                  100.299911                    88.889412   \n","8                   99.673378                    88.626869   \n","9                   99.455437                    88.726418   \n","\n","   Primary completion rate  Literacy rate  Year Country  \n","0                      NaN            NaN  2022     USA  \n","1                      NaN            NaN  2021     USA  \n","2               100.923668            NaN  2020     USA  \n","3               100.489052            NaN  2019     USA  \n","4               100.092697            NaN  2018     USA  \n","5                98.832199            NaN  2017     USA  \n","6                      NaN            NaN  2016     USA  \n","7                      NaN            NaN  2015     USA  \n","8                      NaN            NaN  2014     USA  \n","9                      NaN            NaN  2013     USA  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["data_countries_examples = pd.read_csv(\"countries_example.csv\")\n","data_countries_examples"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"NQlw9J43lxSM"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n"]}],"source":["BASE_URL = 'http://api.worldbank.org/v2/'\n","COUNTRIES = [\"US\", \"IN\", \"CN\", \"JP\", \"CA\", \"GB\", \"ZA\"]\n","INDICATORS = ['SP.POP.TOTL',\n","             'SP.POP.TOTL.FE.IN',\n","             'SP.POP.TOTL.MA.IN',\n","             'SP.DYN.CBRT.IN',\n","             'SP.DYN.CDRT.IN',\n","             'SP.DYN.LE00.MA.IN',\n","             'SP.DYN.LE00.FE.IN',\n","             'SE.PRM.ENRR',\n","             'SE.TER.ENRR',\n","             'SE.PRM.CMPT.ZS',\n","             'SE.ADT.1524.LT.ZS']\n","\n","\n","# If you need other initializations"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"DkzknpDflxSN"},"outputs":[],"source":["def collect_data(countryCode, per_page, start_year, end_year):\n","    dataset = []\n","    year = []\n","    country = []\n","    for indicator in INDICATORS:\n","        url = BASE_URL + 'COUNTRIES/'+ countryCode + '/INDICATORS/' + indicator + '?' + 'date=' + str(start_year) +':' + str(end_year) + '&' + 'per_page=' + str(per_page)\n","        data = requests.get(url).text\n","        info = []\n","        soup = BeautifulSoup(data, 'lxml')\n","        result = soup.find('wb:data')\n","        pages = int(result.get('pages'))\n","        for i in range(1, pages+1):\n","            new_url = url + '&' + 'page=' + str(i)\n","            new_data = requests.get(new_url).text\n","            new_soup = BeautifulSoup(new_data, 'lxml')\n","            new_result = new_soup.findAll('wb:data')\n","            for x in new_result[1:]:\n","                value = x.find('wb:value').text\n","                if value == '':\n","                    value = np.nan\n","                info.append(value)\n","                if indicator == 'SP.POP.TOTL':\n","                    country.append(x.text.split('\\n')[3])\n","                    year.append(x.text.split('\\n')[4])\n","            dataset.append(info)\n","    dataset.append(country)\n","    dataset.append(year)\n","    data = pd.DataFrame({\"Total population\": dataset[0],\n","                         \"Female population\": dataset[1],\n","                         \"Male population\": dataset[2],\n","                         \"Birth rate\": dataset[3],\n","                         \"Death rate\": dataset[4],\n","                         \"Male life expectancy\": dataset[5],\n","                         \"Female life expectancy\": dataset[6],\n","                         \"School enrollment. primary\": dataset[7],\n","                         \"School enrollment, tertiary\": dataset[8],\n","                         \"Primary completion rate\": dataset[9],\n","                         \"Literacy rate\": dataset[10],\n","                         \"Year:\":year, \n","                         \"Country\": country})\n","    return data"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"86Jx-MNnlxSN"},"outputs":[],"source":["def Generate_Countries_Dataset(countryCode_list):\n","    data = pd.DataFrame()\n","    for countryCode in countryCode_list:\n","        data = pd.concat([data, collect_data(countryCode = countryCode, per_page = 100, start_year = 2000, end_year = 2022)], axis=0)\n","    return data"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"6ACVj5TZlxSO"},"outputs":[],"source":["#TEST\n","data_countries = Generate_Countries_Dataset(COUNTRIES)\n","assert data_countries.shape == (161, 13)"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"aeCsh-hHlxSO"},"outputs":[],"source":["# Save to csv file with name coutries.csv\n","data_countries.to_csv('countrie.csv', index = False)\n","#raise NotImplementedError(\"not implement\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
